
@article{roux_using_2016,
	title = {Using Spatialisation to Support Exploratory Search Behaviour},
	url = {https://arrow.tudublin.ie/scschcomdis/89},
	journaltitle = {Dissertations},
	author = {Roux, Clement},
	date = {2016-09},
	file = {"﻿Using Spatialisation to Support Exploratory Search Behaviour" by Clement Roux:/Users/charlesdedampierre/Zotero/storage/F5H3XKGI/89.html:text/html},
}

@misc{jiang_mixtral_2024,
	title = {Mixtral of Experts},
	url = {http://arxiv.org/abs/2401.04088},
	doi = {10.48550/arXiv.2401.04088},
	abstract = {We introduce Mixtral 8x7B, a Sparse Mixture of Experts ({SMoE}) language model. Mixtral has the same architecture as Mistral 7B, with the difference that each layer is composed of 8 feedforward blocks (i.e. experts). For every token, at each layer, a router network selects two experts to process the current state and combine their outputs. Even though each token only sees two experts, the selected experts can be different at each timestep. As a result, each token has access to 47B parameters, but only uses 13B active parameters during inference. Mixtral was trained with a context size of 32k tokens and it outperforms or matches Llama 2 70B and {GPT}-3.5 across all evaluated benchmarks. In particular, Mixtral vastly outperforms Llama 2 70B on mathematics, code generation, and multilingual benchmarks. We also provide a model fine-tuned to follow instructions, Mixtral 8x7B - Instruct, that surpasses {GPT}-3.5 Turbo, Claude-2.1, Gemini Pro, and Llama 2 70B - chat model on human benchmarks. Both the base and instruct models are released under the Apache 2.0 license.},
	number = {{arXiv}:2401.04088},
	publisher = {{arXiv}},
	author = {Jiang, Albert Q. and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and Casas, Diego de las and Hanna, Emma Bou and Bressand, Florian and Lengyel, Gianna and Bour, Guillaume and Lample, Guillaume and Lavaud, Lélio Renard and Saulnier, Lucile and Lachaux, Marie-Anne and Stock, Pierre and Subramanian, Sandeep and Yang, Sophia and Antoniak, Szymon and Scao, Teven Le and Gervet, Théophile and Lavril, Thibaut and Wang, Thomas and Lacroix, Timothée and Sayed, William El},
	urldate = {2024-03-15},
	date = {2024-01-08},
	eprinttype = {arxiv},
	eprint = {2401.04088 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/FUTLCSFK/Jiang et al. - 2024 - Mixtral of Experts.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/6H99BUDX/2401.html:text/html},
}

@misc{gu_mamba_2023,
	title = {Mamba: Linear-Time Sequence Modeling with Selective State Spaces},
	url = {http://arxiv.org/abs/2312.00752},
	doi = {10.48550/arXiv.2312.00752},
	shorttitle = {Mamba},
	abstract = {Foundation models, now powering most of the exciting applications in deep learning, are almost universally based on the Transformer architecture and its core attention module. Many subquadratic-time architectures such as linear attention, gated convolution and recurrent models, and structured state space models ({SSMs}) have been developed to address Transformers' computational inefficiency on long sequences, but they have not performed as well as attention on important modalities such as language. We identify that a key weakness of such models is their inability to perform content-based reasoning, and make several improvements. First, simply letting the {SSM} parameters be functions of the input addresses their weakness with discrete modalities, allowing the model to selectively propagate or forget information along the sequence length dimension depending on the current token. Second, even though this change prevents the use of efficient convolutions, we design a hardware-aware parallel algorithm in recurrent mode. We integrate these selective {SSMs} into a simplified end-to-end neural network architecture without attention or even {MLP} blocks (Mamba). Mamba enjoys fast inference (5\${\textbackslash}times\$ higher throughput than Transformers) and linear scaling in sequence length, and its performance improves on real data up to million-length sequences. As a general sequence model backbone, Mamba achieves state-of-the-art performance across several modalities such as language, audio, and genomics. On language modeling, our Mamba-3B model outperforms Transformers of the same size and matches Transformers twice its size, both in pretraining and downstream evaluation.},
	number = {{arXiv}:2312.00752},
	publisher = {{arXiv}},
	author = {Gu, Albert and Dao, Tri},
	urldate = {2024-03-15},
	date = {2023-12-01},
	eprinttype = {arxiv},
	eprint = {2312.00752 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/QN8SYGLF/Gu and Dao - 2023 - Mamba Linear-Time Sequence Modeling with Selectiv.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/N39N8MJC/2312.html:text/html},
}

@misc{wei_emergent_2022,
	title = {Emergent Abilities of Large Language Models},
	url = {http://arxiv.org/abs/2206.07682},
	doi = {10.48550/arXiv.2206.07682},
	abstract = {Scaling up language models has been shown to predictably improve performance and sample efficiency on a wide range of downstream tasks. This paper instead discusses an unpredictable phenomenon that we refer to as emergent abilities of large language models. We consider an ability to be emergent if it is not present in smaller models but is present in larger models. Thus, emergent abilities cannot be predicted simply by extrapolating the performance of smaller models. The existence of such emergence implies that additional scaling could further expand the range of capabilities of language models.},
	number = {{arXiv}:2206.07682},
	publisher = {{arXiv}},
	author = {Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and Chi, Ed H. and Hashimoto, Tatsunori and Vinyals, Oriol and Liang, Percy and Dean, Jeff and Fedus, William},
	urldate = {2024-03-15},
	date = {2022-10-26},
	eprinttype = {arxiv},
	eprint = {2206.07682 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/FQA8CJIV/Wei et al. - 2022 - Emergent Abilities of Large Language Models.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/QUJD9TD8/2206.html:text/html},
}

@misc{li_starcoder_2023,
	title = {{StarCoder}: may the source be with you!},
	url = {http://arxiv.org/abs/2305.06161},
	doi = {10.48550/arXiv.2305.06161},
	shorttitle = {{StarCoder}},
	abstract = {The {BigCode} community, an open-scientific collaboration working on the responsible development of Large Language Models for Code (Code {LLMs}), introduces {StarCoder} and {StarCoderBase}: 15.5B parameter models with 8K context length, infilling capabilities and fast large-batch inference enabled by multi-query attention. {StarCoderBase} is trained on 1 trillion tokens sourced from The Stack, a large collection of permissively licensed {GitHub} repositories with inspection tools and an opt-out process. We fine-tuned {StarCoderBase} on 35B Python tokens, resulting in the creation of {StarCoder}. We perform the most comprehensive evaluation of Code {LLMs} to date and show that {StarCoderBase} outperforms every open Code {LLM} that supports multiple programming languages and matches or outperforms the {OpenAI} code-cushman-001 model. Furthermore, {StarCoder} outperforms every model that is fine-tuned on Python, can be prompted to achieve 40{\textbackslash}\% pass@1 on {HumanEval}, and still retains its performance on other programming languages. We take several important steps towards a safe open-access model release, including an improved {PII} redaction pipeline and a novel attribution tracing tool, and make the {StarCoder} models publicly available under a more commercially viable version of the Open Responsible {AI} Model license.},
	number = {{arXiv}:2305.06161},
	publisher = {{arXiv}},
	author = {Li, Raymond and Allal, Loubna Ben and Zi, Yangtian and Muennighoff, Niklas and Kocetkov, Denis and Mou, Chenghao and Marone, Marc and Akiki, Christopher and Li, Jia and Chim, Jenny and Liu, Qian and Zheltonozhskii, Evgenii and Zhuo, Terry Yue and Wang, Thomas and Dehaene, Olivier and Davaadorj, Mishig and Lamy-Poirier, Joel and Monteiro, João and Shliazhko, Oleh and Gontier, Nicolas and Meade, Nicholas and Zebaze, Armel and Yee, Ming-Ho and Umapathi, Logesh Kumar and Zhu, Jian and Lipkin, Benjamin and Oblokulov, Muhtasham and Wang, Zhiruo and Murthy, Rudra and Stillerman, Jason and Patel, Siva Sankalp and Abulkhanov, Dmitry and Zocca, Marco and Dey, Manan and Zhang, Zhihan and Fahmy, Nour and Bhattacharyya, Urvashi and Yu, Wenhao and Singh, Swayam and Luccioni, Sasha and Villegas, Paulo and Kunakov, Maxim and Zhdanov, Fedor and Romero, Manuel and Lee, Tony and Timor, Nadav and Ding, Jennifer and Schlesinger, Claire and Schoelkopf, Hailey and Ebert, Jan and Dao, Tri and Mishra, Mayank and Gu, Alex and Robinson, Jennifer and Anderson, Carolyn Jane and Dolan-Gavitt, Brendan and Contractor, Danish and Reddy, Siva and Fried, Daniel and Bahdanau, Dzmitry and Jernite, Yacine and Ferrandis, Carlos Muñoz and Hughes, Sean and Wolf, Thomas and Guha, Arjun and von Werra, Leandro and de Vries, Harm},
	urldate = {2024-03-15},
	date = {2023-12-13},
	eprinttype = {arxiv},
	eprint = {2305.06161 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Programming Languages, Computer Science - Software Engineering},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/X4MEBZMV/Li et al. - 2023 - StarCoder may the source be with you!.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/KGMM6IN4/2305.html:text/html},
}

@misc{bae_security_2021,
	title = {Security and Privacy Issues in Deep Learning},
	url = {http://arxiv.org/abs/1807.11655},
	abstract = {To promote secure and private artificial intelligence ({SPAI}), we review studies on the model security and data privacy of {DNNs}. Model security allows system to behave as intended without being affected by malicious external influences that can compromise its integrity and efficiency. Security attacks can be divided based on when they occur: if an attack occurs during training, it is known as a poisoning attack, and if it occurs during inference (after training) it is termed an evasion attack. Poisoning attacks compromise the training process by corrupting the data with malicious examples, while evasion attacks use adversarial examples to disrupt entire classification process. Defenses proposed against such attacks include techniques to recognize and remove malicious data, train a model to be insensitive to such data, and mask the model's structure and parameters to render attacks more challenging to implement. Furthermore, the privacy of the data involved in model training is also threatened by attacks such as the model-inversion attack, or by dishonest service providers of {AI} applications. To maintain data privacy, several solutions that combine existing data-privacy techniques have been proposed, including differential privacy and modern cryptography techniques. In this paper, we describe the notions of some of methods, e.g., homomorphic encryption, and review their advantages and challenges when implemented in deep-learning models.},
	number = {{arXiv}:1807.11655},
	publisher = {{arXiv}},
	author = {Bae, Ho and Jang, Jaehee and Jung, Dahuin and Jang, Hyemi and Ha, Heonseok and Lee, Hyungyu and Yoon, Sungroh},
	urldate = {2024-03-15},
	date = {2021-03-09},
	eprinttype = {arxiv},
	eprint = {1807.11655 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Cryptography and Security},
	file = {arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/I538CEUI/1807.html:text/html;Full Text PDF:/Users/charlesdedampierre/Zotero/storage/6L62WVL5/Bae et al. - 2021 - Security and Privacy Issues in Deep Learning.pdf:application/pdf},
}

@misc{zhou_making_2023,
	title = {Making Harmful Behaviors Unlearnable for Large Language Models},
	url = {http://arxiv.org/abs/2311.02105},
	doi = {10.48550/arXiv.2311.02105},
	abstract = {Large language models ({LLMs}) have shown great potential as general-purpose {AI} assistants in various domains. To meet the requirements of different applications, {LLMs} are often customized by further fine-tuning. However, the powerful learning ability of {LLMs} not only enables them to acquire new tasks but also makes them susceptible to learning undesired behaviors. For example, even safety-aligned {LLMs} can be easily fine-tuned into harmful assistants as the fine-tuning data often contains implicit or explicit harmful content. Can we train {LLMs} on harmful data without learning harmful behaviors? This paper proposes a controllable training framework that makes harmful behaviors unlearnable during the fine-tuning process. Specifically, we introduce ``security vectors'', a few new parameters that can be separated from the {LLM}, to ensure {LLM}'s responses are consistent with the harmful behavior. Security vectors are activated during fine-tuning, the consistent behavior makes {LLM} believe that such behavior has already been learned, there is no need to further optimize for harmful data. During inference, we can deactivate security vectors to restore the {LLM}'s normal behavior. The experimental results show that the security vectors generated by 100 harmful samples are enough to prevent {LLM} from learning 1000 harmful samples, while preserving the ability to learn other useful information.},
	number = {{arXiv}:2311.02105},
	publisher = {{arXiv}},
	author = {Zhou, Xin and Lu, Yi and Ma, Ruotian and Gui, Tao and Zhang, Qi and Huang, Xuanjing},
	urldate = {2024-03-15},
	date = {2023-11-02},
	eprinttype = {arxiv},
	eprint = {2311.02105 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computers and Society},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/T8MDPY9B/Zhou et al. - 2023 - Making Harmful Behaviors Unlearnable for Large Lan.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/YZGIMIL7/2311.html:text/html},
}

@article{hanna_assessing_2023,
	title = {Assessing Racial and Ethnic Bias in Text Generation for Healthcare-Related Tasks by {ChatGPT}1},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10491360/},
	doi = {10.1101/2023.08.28.23294730},
	abstract = {Large Language Models ({LLM}) are {AI} tools that can respond human-like to voice or free-text commands without training on specific tasks. However, concerns have been raised about their potential racial bias in healthcare tasks. In this study, {ChatGPT} was used to generate healthcare-related text for patients with {HIV}, analyzing data from 100 deidentified electronic health record encounters. Each patient’s data were fed four times with all information remaining the same except for race/ethnicity (African American, Asian, Hispanic White, Non-Hispanic White). The text output was analyzed for sentiment, subjectivity, reading ease, and most used words by race/ethnicity and insurance type. Results showed that instructions for African American, Asian, Hispanic White, and Non-Hispanic White patients had an average polarity of 0.14, 0.14, 0.15, and 0.14, respectively, with an average subjectivity of 0.46 for all races/ethnicities. The differences in polarity and subjectivity across races/ethnicities were not statistically significant. However, there was a statistically significant difference in word frequency across races/ethnicities and a statistically significant difference in subjectivity across insurance types with commercial insurance eliciting the most subjective responses and Medicare and other payer types the lowest. The study suggests that {ChatGPT} is relatively invariant to race/ethnicity and insurance type in terms of linguistic and readability measures. Further studies are needed to validate these results and assess their implications.},
	pages = {2023.08.28.23294730},
	journaltitle = {{medRxiv}},
	shortjournal = {{medRxiv}},
	author = {Hanna, John J. and Wakene, Abdi D. and Lehmann, Christoph U. and Medford, Richard J.},
	urldate = {2024-03-15},
	date = {2023-08-28},
	pmid = {37693388},
	pmcid = {PMC10491360},
	file = {PubMed Central Full Text PDF:/Users/charlesdedampierre/Zotero/storage/38QWIMEP/Hanna et al. - 2023 - Assessing Racial and Ethnic Bias in Text Generatio.pdf:application/pdf},
}

@article{rillig_risks_2023,
	title = {Risks and Benefits of Large Language Models for the Environment},
	volume = {57},
	issn = {0013-936X},
	url = {https://doi.org/10.1021/acs.est.3c01106},
	doi = {10.1021/acs.est.3c01106},
	pages = {3464--3466},
	number = {9},
	journaltitle = {Environmental Science \& Technology},
	shortjournal = {Environ. Sci. Technol.},
	author = {Rillig, Matthias C. and Ågerstrand, Marlene and Bi, Mohan and Gould, Kenneth A. and Sauerland, Uli},
	urldate = {2024-03-15},
	date = {2023-03-07},
	note = {Publisher: American Chemical Society},
	file = {Full Text PDF:/Users/charlesdedampierre/Zotero/storage/S564CFES/Rillig et al. - 2023 - Risks and Benefits of Large Language Models for th.pdf:application/pdf},
}

@misc{liao_ai_2023,
	title = {{AI} Transparency in the Age of {LLMs}: A Human-Centered Research Roadmap},
	url = {http://arxiv.org/abs/2306.01941},
	shorttitle = {{AI} Transparency in the Age of {LLMs}},
	abstract = {The rise of powerful large language models ({LLMs}) brings about tremendous opportunities for innovation but also looming risks for individuals and society at large. We have reached a pivotal moment for ensuring that {LLMs} and {LLM}-infused applications are developed and deployed responsibly. However, a central pillar of responsible {AI} -- transparency -- is largely missing from the current discourse around {LLMs}. It is paramount to pursue new approaches to provide transparency for {LLMs}, and years of research at the intersection of {AI} and human-computer interaction ({HCI}) highlight that we must do so with a human-centered perspective: Transparency is fundamentally about supporting appropriate human understanding, and this understanding is sought by different stakeholders with different goals in different contexts. In this new era of {LLMs}, we must develop and design approaches to transparency by considering the needs of stakeholders in the emerging {LLM} ecosystem, the novel types of {LLM}-infused applications being built, and the new usage patterns and challenges around {LLMs}, all while building on lessons learned about how people process, interact with, and make use of information. We reflect on the unique challenges that arise in providing transparency for {LLMs}, along with lessons learned from {HCI} and responsible {AI} research that has taken a human-centered perspective on {AI} transparency. We then lay out four common approaches that the community has taken to achieve transparency -- model reporting, publishing evaluation results, providing explanations, and communicating uncertainty -- and call out open questions around how these approaches may or may not be applied to {LLMs}. We hope this provides a starting point for discussion and a useful roadmap for future research.},
	number = {{arXiv}:2306.01941},
	publisher = {{arXiv}},
	author = {Liao, Q. Vera and Vaughan, Jennifer Wortman},
	urldate = {2024-03-15},
	date = {2023-08-07},
	eprinttype = {arxiv},
	eprint = {2306.01941 [cs]},
	keywords = {Computer Science - Human-Computer Interaction, Computer Science - Artificial Intelligence, Computer Science - Computers and Society},
	file = {arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/42VIL4AI/2306.html:text/html;Full Text PDF:/Users/charlesdedampierre/Zotero/storage/6PE8N45F/Liao and Vaughan - 2023 - AI Transparency in the Age of LLMs A Human-Center.pdf:application/pdf},
}

@misc{gunasekar_textbooks_2023,
	title = {Textbooks Are All You Need},
	url = {http://arxiv.org/abs/2306.11644},
	doi = {10.48550/arXiv.2306.11644},
	abstract = {We introduce phi-1, a new large language model for code, with significantly smaller size than competing models: phi-1 is a Transformer-based model with 1.3B parameters, trained for 4 days on 8 A100s, using a selection of ``textbook quality" data from the web (6B tokens) and synthetically generated textbooks and exercises with {GPT}-3.5 (1B tokens). Despite this small scale, phi-1 attains pass@1 accuracy 50.6\% on {HumanEval} and 55.5\% on {MBPP}. It also displays surprising emergent properties compared to phi-1-base, our model before our finetuning stage on a dataset of coding exercises, and phi-1-small, a smaller model with 350M parameters trained with the same pipeline as phi-1 that still achieves 45\% on {HumanEval}.},
	number = {{arXiv}:2306.11644},
	publisher = {{arXiv}},
	author = {Gunasekar, Suriya and Zhang, Yi and Aneja, Jyoti and Mendes, Caio César Teodoro and Del Giorno, Allie and Gopi, Sivakanth and Javaheripi, Mojan and Kauffmann, Piero and de Rosa, Gustavo and Saarikivi, Olli and Salim, Adil and Shah, Shital and Behl, Harkirat Singh and Wang, Xin and Bubeck, Sébastien and Eldan, Ronen and Kalai, Adam Tauman and Lee, Yin Tat and Li, Yuanzhi},
	urldate = {2024-03-15},
	date = {2023-10-02},
	eprinttype = {arxiv},
	eprint = {2306.11644 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/A54ZDSEX/Gunasekar et al. - 2023 - Textbooks Are All You Need.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/2P2DITR2/2306.html:text/html},
}

@misc{meister_language_2021,
	title = {Language Model Evaluation Beyond Perplexity},
	url = {http://arxiv.org/abs/2106.00085},
	doi = {10.48550/arXiv.2106.00085},
	abstract = {We propose an alternate approach to quantifying how well language models learn natural language: we ask how well they match the statistical tendencies of natural language. To answer this question, we analyze whether text generated from language models exhibits the statistical tendencies present in the human-generated text on which they were trained. We provide a framework--paired with significance tests--for evaluating the fit of language models to these trends. We find that neural language models appear to learn only a subset of the tendencies considered, but align much more closely with empirical trends than proposed theoretical distributions (when present). Further, the fit to different distributions is highly-dependent on both model architecture and generation strategy. As concrete examples, text generated under the nucleus sampling scheme adheres more closely to the type--token relationship of natural language than text produced using standard ancestral sampling; text from {LSTMs} reflects the natural language distributions over length, stopwords, and symbols surprisingly well.},
	number = {{arXiv}:2106.00085},
	publisher = {{arXiv}},
	author = {Meister, Clara and Cotterell, Ryan},
	urldate = {2024-03-15},
	date = {2021-08-30},
	eprinttype = {arxiv},
	eprint = {2106.00085 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/HXM5E2SD/Meister and Cotterell - 2021 - Language Model Evaluation Beyond Perplexity.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/J3C4TUJG/2106.html:text/html},
}

@misc{lee_deduplicating_2022,
	title = {Deduplicating Training Data Makes Language Models Better},
	url = {http://arxiv.org/abs/2107.06499},
	doi = {10.48550/arXiv.2107.06499},
	abstract = {We find that existing language modeling datasets contain many near-duplicate examples and long repetitive substrings. As a result, over 1\% of the unprompted output of language models trained on these datasets is copied verbatim from the training data. We develop two tools that allow us to deduplicate training datasets -- for example removing from C4 a single 61 word English sentence that is repeated over 60,000 times. Deduplication allows us to train models that emit memorized text ten times less frequently and require fewer train steps to achieve the same or better accuracy. We can also reduce train-test overlap, which affects over 4\% of the validation set of standard datasets, thus allowing for more accurate evaluation. We release code for reproducing our work and performing dataset deduplication at https://github.com/google-research/deduplicate-text-datasets.},
	number = {{arXiv}:2107.06499},
	publisher = {{arXiv}},
	author = {Lee, Katherine and Ippolito, Daphne and Nystrom, Andrew and Zhang, Chiyuan and Eck, Douglas and Callison-Burch, Chris and Carlini, Nicholas},
	urldate = {2024-03-15},
	date = {2022-03-24},
	eprinttype = {arxiv},
	eprint = {2107.06499 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/2GK2FRZT/Lee et al. - 2022 - Deduplicating Training Data Makes Language Models .pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/SC3KZBFI/2107.html:text/html},
}

@misc{zhang_efficient_2023,
	title = {Efficient Toxic Content Detection by Bootstrapping and Distilling Large Language Models},
	url = {http://arxiv.org/abs/2312.08303},
	doi = {10.48550/arXiv.2312.08303},
	abstract = {Toxic content detection is crucial for online services to remove inappropriate content that violates community standards. To automate the detection process, prior works have proposed varieties of machine learning ({ML}) approaches to train Language Models ({LMs}) for toxic content detection. However, both their accuracy and transferability across datasets are limited. Recently, Large Language Models ({LLMs}) have shown promise in toxic content detection due to their superior zero-shot and few-shot in-context learning ability as well as broad transferability on {ML} tasks. However, efficiently designing prompts for {LLMs} remains challenging. Moreover, the high run-time cost of {LLMs} may hinder their deployments in production. To address these challenges, in this work, we propose {BD}-{LLM}, a novel and efficient approach to Bootstrapping and Distilling {LLMs} for toxic content detection. Specifically, we design a novel prompting method named Decision-Tree-of-Thought ({DToT}) to bootstrap {LLMs}' detection performance and extract high-quality rationales. {DToT} can automatically select more fine-grained context to re-prompt {LLMs} when their responses lack confidence. Additionally, we use the rationales extracted via {DToT} to fine-tune student {LMs}. Our experimental results on various datasets demonstrate that {DToT} can improve the accuracy of {LLMs} by up to 4.6\%. Furthermore, student {LMs} fine-tuned with rationales extracted via {DToT} outperform baselines on all datasets with up to 16.9{\textbackslash}\% accuracy improvement, while being more than 60x smaller than conventional {LLMs}. Finally, we observe that student {LMs} fine-tuned with rationales exhibit better cross-dataset transferability.},
	number = {{arXiv}:2312.08303},
	publisher = {{arXiv}},
	author = {Zhang, Jiang and Wu, Qiong and Xu, Yiming and Cao, Cheng and Du, Zheng and Psounis, Konstantinos},
	urldate = {2024-03-15},
	date = {2023-12-13},
	eprinttype = {arxiv},
	eprint = {2312.08303 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/8UMBA3MW/Zhang et al. - 2023 - Efficient Toxic Content Detection by Bootstrapping.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/XB7SDNKS/2312.html:text/html},
}

@article{kwak_frameaxis_2021,
	title = {{FrameAxis}: Characterizing Microframe Bias and Intensity with Word Embedding},
	volume = {7},
	issn = {2376-5992},
	url = {http://arxiv.org/abs/2002.08608},
	doi = {10.7717/peerj-cs.644},
	shorttitle = {{FrameAxis}},
	abstract = {Framing is a process of emphasizing a certain aspect of an issue over the others, nudging readers or listeners towards different positions on the issue even without making a biased argument. \{Here, we propose {FrameAxis}, a method for characterizing documents by identifying the most relevant semantic axes ("microframes") that are overrepresented in the text using word embedding. Our unsupervised approach can be readily applied to large datasets because it does not require manual annotations. It can also provide nuanced insights by considering a rich set of semantic axes. {FrameAxis} is designed to quantitatively tease out two important dimensions of how microframes are used in the text. {\textbackslash}textit\{Microframe bias\} captures how biased the text is on a certain microframe, and {\textbackslash}textit\{microframe intensity\} shows how actively a certain microframe is used. Together, they offer a detailed characterization of the text. We demonstrate that microframes with the highest bias and intensity well align with sentiment, topic, and partisan spectrum by applying {FrameAxis} to multiple datasets from restaurant reviews to political news.\} The existing domain knowledge can be incorporated into {FrameAxis} \{by using custom microframes and by using {FrameAxis} as an iterative exploratory analysis instrument.\} Additionally, we propose methods for explaining the results of {FrameAxis} at the level of individual words and documents. Our method may accelerate scalable and sophisticated computational analyses of framing across disciplines.},
	pages = {e644},
	journaltitle = {{PeerJ} Computer Science},
	author = {Kwak, Haewoon and An, Jisun and Jing, Elise and Ahn, Yong-Yeol},
	urldate = {2024-03-15},
	date = {2021-07-22},
	eprinttype = {arxiv},
	eprint = {2002.08608 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society, I.2.7},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/9FWNSWPC/Kwak et al. - 2021 - FrameAxis Characterizing Microframe Bias and Inte.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/NX6U9ZM7/2002.html:text/html},
}

@article{hografer_state_2020,
	title = {The State of the Art in Map-Like Visualization},
	volume = {39},
	rights = {© 2020 The Author(s) Computer Graphics Forum © 2020 The Eurographics Association and John Wiley \& Sons Ltd. Published by John Wiley \& Sons Ltd.},
	issn = {1467-8659},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14031},
	doi = {10.1111/cgf.14031},
	abstract = {Cartographic maps have been shown to provide cognitive benefits when interpreting data in relation to a geographic location. In visualization, the term map-like describes techniques that incorporate characteristics of cartographic maps in their representation of abstract data. However, the field of map-like visualization is vast and currently lacks a clear classification of the existing techniques. Moreover, choosing the right technique to support a particular visualization task is further complicated, as techniques are scattered across different domains, with each considering different characteristics as map-like. In this paper, we give an overview of the literature on map-like visualization and provide a hierarchical classification of existing techniques along two general perspectives: imitation and schematization of cartographic maps. Each perspective is further divided into four principal categories that group common map-like techniques along the visual primitives they affect. We further discuss this classification from a task-centered view and highlight open research questions.},
	pages = {647--674},
	number = {3},
	journaltitle = {Computer Graphics Forum},
	author = {Hogräfer, Marius and Heitzler, Magnus and Schulz, Hans-Jörg},
	urldate = {2024-03-15},
	date = {2020},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.14031},
	file = {Snapshot:/Users/charlesdedampierre/Zotero/storage/WIEAU7NB/cgf.html:text/html},
}

@misc{dodge_documenting_2021,
	title = {Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus},
	url = {http://arxiv.org/abs/2104.08758},
	doi = {10.48550/arXiv.2104.08758},
	shorttitle = {Documenting Large Webtext Corpora},
	abstract = {Large language models have led to remarkable progress on many {NLP} tasks, and researchers are turning to ever-larger text corpora to train them. Some of the largest corpora available are made by scraping significant portions of the internet, and are frequently introduced with only minimal documentation. In this work we provide some of the first documentation for the Colossal Clean Crawled Corpus (C4; Raffel et al., 2020), a dataset created by applying a set of filters to a single snapshot of Common Crawl. We begin by investigating where the data came from, and find a significant amount of text from unexpected sources like patents and {US} military websites. Then we explore the content of the text itself, and find machine-generated text (e.g., from machine translation systems) and evaluation examples from other benchmark {NLP} datasets. To understand the impact of the filters applied to create this dataset, we evaluate the text that was removed, and show that blocklist filtering disproportionately removes text from and about minority individuals. Finally, we conclude with some recommendations for how to created and document web-scale datasets from a scrape of the internet.},
	number = {{arXiv}:2104.08758},
	publisher = {{arXiv}},
	author = {Dodge, Jesse and Sap, Maarten and Marasović, Ana and Agnew, William and Ilharco, Gabriel and Groeneveld, Dirk and Mitchell, Margaret and Gardner, Matt},
	urldate = {2024-03-15},
	date = {2021-09-30},
	eprinttype = {arxiv},
	eprint = {2104.08758 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/UHK8JMVG/Dodge et al. - 2021 - Documenting Large Webtext Corpora A Case Study on.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/HU4Z63MY/2104.html:text/html},
}

@misc{zhu_multimodal_2023,
	title = {Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved with Text},
	url = {http://arxiv.org/abs/2304.06939},
	doi = {10.48550/arXiv.2304.06939},
	shorttitle = {Multimodal C4},
	abstract = {In-context vision and language models like Flamingo support arbitrarily interleaved sequences of images and text as input. This format not only enables few-shot learning via interleaving independent supervised (image, text) examples, but also, more complex prompts involving interaction between images, e.g., "What do image A and image B have in common?" To support this interface, pretraining occurs over web corpora that similarly contain interleaved images+text. To date, however, large-scale data of this form have not been publicly available. We release Multimodal C4, an augmentation of the popular text-only C4 corpus with images interleaved. We use a linear assignment algorithm to place images into longer bodies of text using {CLIP} features, a process that we show outperforms alternatives. Multimodal C4 spans everyday topics like cooking, travel, technology, etc. A manual inspection of a random sample of documents shows that a vast majority (88\%) of images are topically relevant, and that linear assignment frequently selects individual sentences specifically well-aligned with each image (80\%). After filtering {NSFW} images, ads, etc., the resulting corpus consists of 101.2M documents with 571M images interleaved in 43B English tokens.},
	number = {{arXiv}:2304.06939},
	publisher = {{arXiv}},
	author = {Zhu, Wanrong and Hessel, Jack and Awadalla, Anas and Gadre, Samir Yitzhak and Dodge, Jesse and Fang, Alex and Yu, Youngjae and Schmidt, Ludwig and Wang, William Yang and Choi, Yejin},
	urldate = {2024-03-15},
	date = {2023-10-28},
	eprinttype = {arxiv},
	eprint = {2304.06939 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/YNTYZD6P/Zhu et al. - 2023 - Multimodal C4 An Open, Billion-scale Corpus of Im.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/EGXR4CTP/2304.html:text/html},
}

@misc{touvron_llama_2023,
	title = {{LLaMA}: Open and Efficient Foundation Language Models},
	url = {http://arxiv.org/abs/2302.13971},
	doi = {10.48550/arXiv.2302.13971},
	shorttitle = {{LLaMA}},
	abstract = {We introduce {LLaMA}, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, {LLaMA}-13B outperforms {GPT}-3 (175B) on most benchmarks, and {LLaMA}-65B is competitive with the best models, Chinchilla-70B and {PaLM}-540B. We release all our models to the research community.},
	number = {{arXiv}:2302.13971},
	publisher = {{arXiv}},
	author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothée and Rozière, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
	urldate = {2024-03-15},
	date = {2023-02-27},
	eprinttype = {arxiv},
	eprint = {2302.13971 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/BR2NFZI6/Touvron et al. - 2023 - LLaMA Open and Efficient Foundation Language Mode.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/KWKNW95J/2302.html:text/html},
}

@misc{mckinzie_mm1_2024,
	title = {{MM}1: Methods, Analysis \& Insights from Multimodal {LLM} Pre-training},
	url = {http://arxiv.org/abs/2403.09611},
	shorttitle = {{MM}1},
	abstract = {In this work, we discuss building performant Multimodal Large Language Models ({MLLMs}). In particular, we study the importance of various architecture components and data choices. Through careful and comprehensive ablations of the image encoder, the vision language connector, and various pre-training data choices, we identified several crucial design lessons. For example, we demonstrate that for large-scale multimodal pre-training using a careful mix of image-caption, interleaved image-text, and text-only data is crucial for achieving state-of-the-art ({SOTA}) few-shot results across multiple benchmarks, compared to other published pre-training results. Further, we show that the image encoder together with image resolution and the image token count has substantial impact, while the vision-language connector design is of comparatively negligible importance. By scaling up the presented recipe, we build {MM}1, a family of multimodal models up to 30B parameters, consisting of both dense models and mixture-of-experts ({MoE}) variants, that are {SOTA} in pre-training metrics and achieve competitive performance after supervised fine-tuning on a range of established multimodal benchmarks. Thanks to large-scale pre-training, {MM}1 enjoys appealing properties such as enhanced in-context learning, and multi-image reasoning, enabling few-shot chain-of-thought prompting.},
	number = {{arXiv}:2403.09611},
	publisher = {{arXiv}},
	author = {{McKinzie}, Brandon and Gan, Zhe and Fauconnier, Jean-Philippe and Dodge, Sam and Zhang, Bowen and Dufter, Philipp and Shah, Dhruti and Du, Xianzhi and Peng, Futang and Weers, Floris and Belyi, Anton and Zhang, Haotian and Singh, Karanjeet and Kang, Doug and Hè, Hongyu and Schwarzer, Max and Gunter, Tom and Kong, Xiang and Zhang, Aonan and Wang, Jianyu and Wang, Chong and Du, Nan and Lei, Tao and Wiseman, Sam and Lee, Mark and Wang, Zirui and Pang, Ruoming and Grasch, Peter and Toshev, Alexander and Yang, Yinfei},
	urldate = {2024-03-16},
	date = {2024-03-14},
	eprinttype = {arxiv},
	eprint = {2403.09611 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/5IF95H9A/2403.html:text/html;Full Text PDF:/Users/charlesdedampierre/Zotero/storage/DDMP8X69/McKinzie et al. - 2024 - MM1 Methods, Analysis & Insights from Multimodal .pdf:application/pdf},
}

@misc{devlin_bert_2019,
	title = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},
	url = {http://arxiv.org/abs/1810.04805},
	doi = {10.48550/arXiv.1810.04805},
	shorttitle = {{BERT}},
	abstract = {We introduce a new language representation model called {BERT}, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, {BERT} is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained {BERT} model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. {BERT} is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the {GLUE} score to 80.5\% (7.7\% point absolute improvement), {MultiNLI} accuracy to 86.7\% (4.6\% absolute improvement), {SQuAD} v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and {SQuAD} v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	number = {{arXiv}:1810.04805},
	publisher = {{arXiv}},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	urldate = {2024-03-17},
	date = {2019-05-24},
	eprinttype = {arxiv},
	eprint = {1810.04805 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/YUIYGEWE/Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/QTDZ59HD/1810.html:text/html},
}

@misc{brown_language_2020,
	title = {Language Models are Few-Shot Learners},
	url = {http://arxiv.org/abs/2005.14165},
	doi = {10.48550/arXiv.2005.14165},
	abstract = {Recent work has demonstrated substantial gains on many {NLP} tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current {NLP} systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train {GPT}-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, {GPT}-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. {GPT}-3 achieves strong performance on many {NLP} datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where {GPT}-3's few-shot learning still struggles, as well as some datasets where {GPT}-3 faces methodological issues related to training on large web corpora. Finally, we find that {GPT}-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of {GPT}-3 in general.},
	number = {{arXiv}:2005.14165},
	publisher = {{arXiv}},
	author = {Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and {McCandlish}, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
	urldate = {2024-03-17},
	date = {2020-07-22},
	eprinttype = {arxiv},
	eprint = {2005.14165 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/ZLM5JQKC/Brown et al. - 2020 - Language Models are Few-Shot Learners.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/HBEG7Z3S/2005.html:text/html},
}

@misc{vaswani_attention_2023,
	title = {Attention Is All You Need},
	url = {http://arxiv.org/abs/1706.03762},
	doi = {10.48550/arXiv.1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 {BLEU} on the {WMT} 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 {BLEU}. On the {WMT} 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art {BLEU} score of 41.8 after training for 3.5 days on eight {GPUs}, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	number = {{arXiv}:1706.03762},
	publisher = {{arXiv}},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	urldate = {2024-03-17},
	date = {2023-08-01},
	eprinttype = {arxiv},
	eprint = {1706.03762 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/5VYQBXR8/Vaswani et al. - 2023 - Attention Is All You Need.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/IF5KD4GN/1706.html:text/html},
}

@inproceedings{huang_towards_2023,
	location = {Toronto, Canada},
	title = {Towards Reasoning in Large Language Models: A Survey},
	url = {https://aclanthology.org/2023.findings-acl.67},
	doi = {10.18653/v1/2023.findings-acl.67},
	shorttitle = {Towards Reasoning in Large Language Models},
	abstract = {Reasoning is a fundamental aspect of human intelligence that plays a crucial role in activities such as problem solving, decision making, and critical thinking. In recent years, large language models ({LLMs}) have made significant progress in natural language processing, and there is observation that these models may exhibit reasoning abilities when they are sufficiently large. However, it is not yet clear to what extent {LLMs} are capable of reasoning. This paper provides a comprehensive overview of the current state of knowledge on reasoning in {LLMs}, including techniques for improving and eliciting reasoning in these models, methods and benchmarks for evaluating reasoning abilities, findings and implications of previous research in this field, and suggestions on future directions. Our aim is to provide a detailed and up-to-date review of this topic and stimulate meaningful discussion and future work.},
	eventtitle = {Findings 2023},
	pages = {1049--1065},
	booktitle = {Findings of the Association for Computational Linguistics: {ACL} 2023},
	publisher = {Association for Computational Linguistics},
	author = {Huang, Jie and Chang, Kevin Chen-Chuan},
	editor = {Rogers, Anna and Boyd-Graber, Jordan and Okazaki, Naoaki},
	urldate = {2024-03-17},
	date = {2023-07},
	file = {Full Text PDF:/Users/charlesdedampierre/Zotero/storage/SA5F2Y2T/Huang and Chang - 2023 - Towards Reasoning in Large Language Models A Surv.pdf:application/pdf},
}

@misc{azerbayev_llemma_2023,
	title = {Llemma: An Open Language Model For Mathematics},
	url = {http://arxiv.org/abs/2310.10631},
	doi = {10.48550/arXiv.2310.10631},
	shorttitle = {Llemma},
	abstract = {We present Llemma, a large language model for mathematics. We continue pretraining Code Llama on the Proof-Pile-2, a mixture of scientific papers, web data containing mathematics, and mathematical code, yielding Llemma. On the {MATH} benchmark Llemma outperforms all known open base models, as well as the unreleased Minerva model suite on an equi-parameter basis. Moreover, Llemma is capable of tool use and formal theorem proving without any further finetuning. We openly release all artifacts, including 7 billion and 34 billion parameter models, the Proof-Pile-2, and code to replicate our experiments.},
	number = {{arXiv}:2310.10631},
	publisher = {{arXiv}},
	author = {Azerbayev, Zhangir and Schoelkopf, Hailey and Paster, Keiran and Santos, Marco Dos and {McAleer}, Stephen and Jiang, Albert Q. and Deng, Jia and Biderman, Stella and Welleck, Sean},
	urldate = {2024-03-17},
	date = {2023-11-30},
	eprinttype = {arxiv},
	eprint = {2310.10631 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Logic in Computer Science},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/4MATA8JA/Azerbayev et al. - 2023 - Llemma An Open Language Model For Mathematics.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/LCQGAS5Y/2310.html:text/html},
}

@misc{omiye_large_2023,
	title = {Large language models in medicine: the potentials and pitfalls},
	url = {http://arxiv.org/abs/2309.00087},
	shorttitle = {Large language models in medicine},
	abstract = {Large language models ({LLMs}) have been applied to tasks in healthcare, ranging from medical exam questions to responding to patient questions. With increasing institutional partnerships between companies producing {LLMs} and healthcare systems, real world clinical application is coming closer to reality. As these models gain traction, it is essential for healthcare practitioners to understand what {LLMs} are, their development, their current and potential applications, and the associated pitfalls when utilized in medicine. This review and accompanying tutorial aim to give an overview of these topics to aid healthcare practitioners in understanding the rapidly changing landscape of {LLMs} as applied to medicine.},
	number = {{arXiv}:2309.00087},
	publisher = {{arXiv}},
	author = {Omiye, Jesutofunmi A. and Gui, Haiwen and Rezaei, Shawheen J. and Zou, James and Daneshjou, Roxana},
	urldate = {2024-03-17},
	date = {2023-08-31},
	eprinttype = {arxiv},
	eprint = {2309.00087 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Computers and Society},
	file = {arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/BFGEPJUG/2309.html:text/html;Full Text PDF:/Users/charlesdedampierre/Zotero/storage/J7QPAAVZ/Omiye et al. - 2023 - Large language models in medicine the potentials .pdf:application/pdf},
}

@misc{hoffmann_training_2022,
	title = {Training Compute-Optimal Large Language Models},
	url = {http://arxiv.org/abs/2203.15556},
	doi = {10.48550/arXiv.2203.15556},
	abstract = {We investigate the optimal model size and number of tokens for training a transformer language model under a given compute budget. We find that current large language models are significantly undertrained, a consequence of the recent focus on scaling language models whilst keeping the amount of training data constant. By training over 400 language models ranging from 70 million to over 16 billion parameters on 5 to 500 billion tokens, we find that for compute-optimal training, the model size and the number of training tokens should be scaled equally: for every doubling of model size the number of training tokens should also be doubled. We test this hypothesis by training a predicted compute-optimal model, Chinchilla, that uses the same compute budget as Gopher but with 70B parameters and 4\${\textbackslash}times\$ more more data. Chinchilla uniformly and significantly outperforms Gopher (280B), {GPT}-3 (175B), Jurassic-1 (178B), and Megatron-Turing {NLG} (530B) on a large range of downstream evaluation tasks. This also means that Chinchilla uses substantially less compute for fine-tuning and inference, greatly facilitating downstream usage. As a highlight, Chinchilla reaches a state-of-the-art average accuracy of 67.5\% on the {MMLU} benchmark, greater than a 7\% improvement over Gopher.},
	number = {{arXiv}:2203.15556},
	publisher = {{arXiv}},
	author = {Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and Hennigan, Tom and Noland, Eric and Millican, Katie and Driessche, George van den and Damoc, Bogdan and Guy, Aurelia and Osindero, Simon and Simonyan, Karen and Elsen, Erich and Rae, Jack W. and Vinyals, Oriol and Sifre, Laurent},
	urldate = {2024-03-17},
	date = {2022-03-29},
	eprinttype = {arxiv},
	eprint = {2203.15556 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/FFN3EC9H/Hoffmann et al. - 2022 - Training Compute-Optimal Large Language Models.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/JR3B9M2L/2203.html:text/html},
}

@misc{gao_pile_2020,
	title = {The Pile: An 800GB Dataset of Diverse Text for Language Modeling},
	url = {http://arxiv.org/abs/2101.00027},
	doi = {10.48550/arXiv.2101.00027},
	shorttitle = {The Pile},
	abstract = {Recent work has demonstrated that increased training dataset diversity improves general cross-domain knowledge and downstream generalization capability for large-scale language models. With this in mind, we present {\textbackslash}textit\{the Pile\}: an 825 {GiB} English text corpus targeted at training large-scale language models. The Pile is constructed from 22 diverse high-quality subsets -- both existing and newly constructed -- many of which derive from academic or professional sources. Our evaluation of the untuned performance of {GPT}-2 and {GPT}-3 on the Pile shows that these models struggle on many of its components, such as academic writing. Conversely, models trained on the Pile improve significantly over both Raw {CC} and {CC}-100 on all components of the Pile, while improving performance on downstream evaluations. Through an in-depth exploratory analysis, we document potentially concerning aspects of the data for prospective users. We make publicly available the code used in its construction.},
	number = {{arXiv}:2101.00027},
	publisher = {{arXiv}},
	author = {Gao, Leo and Biderman, Stella and Black, Sid and Golding, Laurence and Hoppe, Travis and Foster, Charles and Phang, Jason and He, Horace and Thite, Anish and Nabeshima, Noa and Presser, Shawn and Leahy, Connor},
	urldate = {2024-03-17},
	date = {2020-12-31},
	eprinttype = {arxiv},
	eprint = {2101.00027 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/L3FVUMQ8/Gao et al. - 2020 - The Pile An 800GB Dataset of Diverse Text for Lan.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/M4PSUGLL/2101.html:text/html},
}

@misc{taylor_galactica_2022,
	title = {Galactica: A Large Language Model for Science},
	url = {http://arxiv.org/abs/2211.09085},
	doi = {10.48550/arXiv.2211.09085},
	shorttitle = {Galactica},
	abstract = {Information overload is a major obstacle to scientific progress. The explosive growth in scientific literature and data has made it ever harder to discover useful insights in a large mass of information. Today scientific knowledge is accessed through search engines, but they are unable to organize scientific knowledge alone. In this paper we introduce Galactica: a large language model that can store, combine and reason about scientific knowledge. We train on a large scientific corpus of papers, reference material, knowledge bases and many other sources. We outperform existing models on a range of scientific tasks. On technical knowledge probes such as {LaTeX} equations, Galactica outperforms the latest {GPT}-3 by 68.2\% versus 49.0\%. Galactica also performs well on reasoning, outperforming Chinchilla on mathematical {MMLU} by 41.3\% to 35.7\%, and {PaLM} 540B on {MATH} with a score of 20.4\% versus 8.8\%. It also sets a new state-of-the-art on downstream tasks such as {PubMedQA} and {MedMCQA} dev of 77.6\% and 52.9\%. And despite not being trained on a general corpus, Galactica outperforms {BLOOM} and {OPT}-175B on {BIG}-bench. We believe these results demonstrate the potential for language models as a new interface for science. We open source the model for the benefit of the scientific community.},
	number = {{arXiv}:2211.09085},
	publisher = {{arXiv}},
	author = {Taylor, Ross and Kardas, Marcin and Cucurull, Guillem and Scialom, Thomas and Hartshorn, Anthony and Saravia, Elvis and Poulton, Andrew and Kerkez, Viktor and Stojnic, Robert},
	urldate = {2024-03-17},
	date = {2022-11-16},
	eprinttype = {arxiv},
	eprint = {2211.09085 [cs, stat]},
	keywords = {Computer Science - Computation and Language, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/KWVX2PYD/Taylor et al. - 2022 - Galactica A Large Language Model for Science.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/JLPEBEZJ/2211.html:text/html},
}

@misc{black_gpt-neox-20b_2022,
	title = {{GPT}-{NeoX}-20B: An Open-Source Autoregressive Language Model},
	url = {http://arxiv.org/abs/2204.06745},
	doi = {10.48550/arXiv.2204.06745},
	shorttitle = {{GPT}-{NeoX}-20B},
	abstract = {We introduce {GPT}-{NeoX}-20B, a 20 billion parameter autoregressive language model trained on the Pile, whose weights will be made freely and openly available to the public through a permissive license. It is, to the best of our knowledge, the largest dense autoregressive model that has publicly available weights at the time of submission. In this work, we describe {\textbackslash}model\{\}'s architecture and training and evaluate its performance on a range of language-understanding, mathematics, and knowledge-based tasks. We find that {GPT}-{NeoX}-20B is a particularly powerful few-shot reasoner and gains far more in performance when evaluated five-shot than similarly sized {GPT}-3 and {FairSeq} models. We open-source the training and evaluation code, as well as the model weights, at https://github.com/{EleutherAI}/gpt-neox.},
	number = {{arXiv}:2204.06745},
	publisher = {{arXiv}},
	author = {Black, Sid and Biderman, Stella and Hallahan, Eric and Anthony, Quentin and Gao, Leo and Golding, Laurence and He, Horace and Leahy, Connor and {McDonell}, Kyle and Phang, Jason and Pieler, Michael and Prashanth, {USVSN} Sai and Purohit, Shivanshu and Reynolds, Laria and Tow, Jonathan and Wang, Ben and Weinbach, Samuel},
	urldate = {2024-03-17},
	date = {2022-04-14},
	eprinttype = {arxiv},
	eprint = {2204.06745 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/AUTJRL4K/Black et al. - 2022 - GPT-NeoX-20B An Open-Source Autoregressive Langua.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/UYYH3QVZ/2204.html:text/html},
}

@misc{ai_yi_2024,
	title = {Yi: Open Foundation Models by 01.{AI}},
	url = {http://arxiv.org/abs/2403.04652},
	doi = {10.48550/arXiv.2403.04652},
	shorttitle = {Yi},
	abstract = {We introduce the Yi model family, a series of language and multimodal models that demonstrate strong multi-dimensional capabilities. The Yi model family is based on 6B and 34B pretrained language models, then we extend them to chat models, 200K long context models, depth-upscaled models, and vision-language models. Our base models achieve strong performance on a wide range of benchmarks like {MMLU}, and our finetuned chat models deliver strong human preference rate on major evaluation platforms like {AlpacaEval} and Chatbot Arena. Building upon our scalable super-computing infrastructure and the classical transformer architecture, we attribute the performance of Yi models primarily to its data quality resulting from our data-engineering efforts. For pretraining, we construct 3.1 trillion tokens of English and Chinese corpora using a cascaded data deduplication and quality filtering pipeline. For finetuning, we polish a small scale (less than 10K) instruction dataset over multiple iterations such that every single instance has been verified directly by our machine learning engineers. For vision-language, we combine the chat language model with a vision transformer encoder and train the model to align visual representations to the semantic space of the language model. We further extend the context length to 200K through lightweight continual pretraining and demonstrate strong needle-in-a-haystack retrieval performance. We show that extending the depth of the pretrained checkpoint through continual pretraining further improves performance. We believe that given our current results, continuing to scale up model parameters using thoroughly optimized data will lead to even stronger frontier models.},
	number = {{arXiv}:2403.04652},
	publisher = {{arXiv}},
	author = {{AI}, 01 and Young, Alex and Chen, Bei and Li, Chao and Huang, Chengen and Zhang, Ge and Zhang, Guanwei and Li, Heng and Zhu, Jiangcheng and Chen, Jianqun and Chang, Jing and Yu, Kaidong and Liu, Peng and Liu, Qiang and Yue, Shawn and Yang, Senbin and Yang, Shiming and Yu, Tao and Xie, Wen and Huang, Wenhao and Hu, Xiaohui and Ren, Xiaoyi and Niu, Xinyao and Nie, Pengcheng and Xu, Yuchi and Liu, Yudong and Wang, Yue and Cai, Yuxuan and Gu, Zhenyu and Liu, Zhiyuan and Dai, Zonghong},
	urldate = {2024-03-17},
	date = {2024-03-07},
	eprinttype = {arxiv},
	eprint = {2403.04652 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/ESG4ML6P/AI et al. - 2024 - Yi Open Foundation Models by 01.AI.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/S8GVKMA3/2403.html:text/html},
}

@misc{li_digger_2024,
	title = {Digger: Detecting Copyright Content Mis-usage in Large Language Model Training},
	url = {http://arxiv.org/abs/2401.00676},
	doi = {10.48550/arXiv.2401.00676},
	shorttitle = {Digger},
	abstract = {Pre-training, which utilizes extensive and varied datasets, is a critical factor in the success of Large Language Models ({LLMs}) across numerous applications. However, the detailed makeup of these datasets is often not disclosed, leading to concerns about data security and potential misuse. This is particularly relevant when copyrighted material, still under legal protection, is used inappropriately, either intentionally or unintentionally, infringing on the rights of the authors. In this paper, we introduce a detailed framework designed to detect and assess the presence of content from potentially copyrighted books within the training datasets of {LLMs}. This framework also provides a confidence estimation for the likelihood of each content sample's inclusion. To validate our approach, we conduct a series of simulated experiments, the results of which affirm the framework's effectiveness in identifying and addressing instances of content misuse in {LLM} training processes. Furthermore, we investigate the presence of recognizable quotes from famous literary works within these datasets. The outcomes of our study have significant implications for ensuring the ethical use of copyrighted materials in the development of {LLMs}, highlighting the need for more transparent and responsible data management practices in this field.},
	number = {{arXiv}:2401.00676},
	publisher = {{arXiv}},
	author = {Li, Haodong and Deng, Gelei and Liu, Yi and Wang, Kailong and Li, Yuekang and Zhang, Tianwei and Liu, Yang and Xu, Guoai and Xu, Guosheng and Wang, Haoyu},
	urldate = {2024-03-17},
	date = {2024-01-01},
	eprinttype = {arxiv},
	eprint = {2401.00676 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Cryptography and Security},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/NU8TIUUM/Li et al. - 2024 - Digger Detecting Copyright Content Mis-usage in L.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/V45UM8CT/2401.html:text/html},
}

@misc{penedo_refinedweb_2023,
	title = {The {RefinedWeb} Dataset for Falcon {LLM}: Outperforming Curated Corpora with Web Data, and Web Data Only},
	url = {http://arxiv.org/abs/2306.01116},
	doi = {10.48550/arXiv.2306.01116},
	shorttitle = {The {RefinedWeb} Dataset for Falcon {LLM}},
	abstract = {Large language models are commonly trained on a mixture of filtered web data and curated high-quality corpora, such as social media conversations, books, or technical papers. This curation process is believed to be necessary to produce performant models with broad zero-shot generalization abilities. However, as larger models requiring pretraining on trillions of tokens are considered, it is unclear how scalable is curation and whether we will run out of unique high-quality data soon. At variance with previous beliefs, we show that properly filtered and deduplicated web data alone can lead to powerful models; even significantly outperforming models from the state-of-the-art trained on The Pile. Despite extensive filtering, the high-quality data we extract from the web is still plentiful, and we are able to obtain five trillion tokens from {CommonCrawl}. We publicly release an extract of 600 billion tokens from our {RefinedWeb} dataset, and 1.3/7.5B parameters language models trained on it.},
	number = {{arXiv}:2306.01116},
	publisher = {{arXiv}},
	author = {Penedo, Guilherme and Malartic, Quentin and Hesslow, Daniel and Cojocaru, Ruxandra and Cappelli, Alessandro and Alobeidli, Hamza and Pannier, Baptiste and Almazrouei, Ebtesam and Launay, Julien},
	urldate = {2024-03-17},
	date = {2023-06-01},
	eprinttype = {arxiv},
	eprint = {2306.01116 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/XFT3L8FT/Penedo et al. - 2023 - The RefinedWeb Dataset for Falcon LLM Outperformi.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/UBPQTLP4/2306.html:text/html},
}

@misc{kopf_openassistant_2023,
	title = {{OpenAssistant} Conversations -- Democratizing Large Language Model Alignment},
	url = {http://arxiv.org/abs/2304.07327},
	doi = {10.48550/arXiv.2304.07327},
	abstract = {Aligning large language models ({LLMs}) with human preferences has proven to drastically improve usability and has driven rapid adoption as demonstrated by {ChatGPT}. Alignment techniques such as supervised fine-tuning ({SFT}) and reinforcement learning from human feedback ({RLHF}) greatly reduce the required skill and domain knowledge to effectively harness the capabilities of {LLMs}, increasing their accessibility and utility across various domains. However, state-of-the-art alignment techniques like {RLHF} rely on high-quality human feedback data, which is expensive to create and often remains proprietary. In an effort to democratize research on large-scale alignment, we release {OpenAssistant} Conversations, a human-generated, human-annotated assistant-style conversation corpus consisting of 161,443 messages in 35 different languages, annotated with 461,292 quality ratings, resulting in over 10,000 complete and fully annotated conversation trees. The corpus is a product of a worldwide crowd-sourcing effort involving over 13,500 volunteers. Models trained on {OpenAssistant} Conversations show consistent improvements on standard benchmarks over respective base models. We release our code and data under a fully permissive licence.},
	number = {{arXiv}:2304.07327},
	publisher = {{arXiv}},
	author = {Köpf, Andreas and Kilcher, Yannic and von Rütte, Dimitri and Anagnostidis, Sotiris and Tam, Zhi-Rui and Stevens, Keith and Barhoum, Abdullah and Duc, Nguyen Minh and Stanley, Oliver and Nagyfi, Richárd and {ES}, Shahul and Suri, Sameer and Glushkov, David and Dantuluri, Arnav and Maguire, Andrew and Schuhmann, Christoph and Nguyen, Huu and Mattick, Alexander},
	urldate = {2024-03-17},
	date = {2023-10-31},
	eprinttype = {arxiv},
	eprint = {2304.07327 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, I.2},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/7TQ7HHGW/Köpf et al. - 2023 - OpenAssistant Conversations -- Democratizing Large.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/V4KTFNBE/2304.html:text/html},
}

@online{noauthor_comparative_nodate,
	title = {A Comparative Study on Annotation Quality of Crowdsourcing and {LLM} via Label Aggregation},
	url = {https://arxiv.org/html/2401.09760v1},
	urldate = {2024-03-17},
	file = {A Comparative Study on Annotation Quality of Crowdsourcing and LLM via Label Aggregation:/Users/charlesdedampierre/Zotero/storage/R563CIP8/2401.html:text/html},
}

@misc{li_comparative_2024,
	title = {A Comparative Study on Annotation Quality of Crowdsourcing and {LLM} via Label Aggregation},
	url = {http://arxiv.org/abs/2401.09760},
	doi = {10.48550/arXiv.2401.09760},
	abstract = {Whether Large Language Models ({LLMs}) can outperform crowdsourcing on the data annotation task is attracting interest recently. Some works verified this issue with the average performance of individual crowd workers and {LLM} workers on some specific {NLP} tasks by collecting new datasets. However, on the one hand, existing datasets for the studies of annotation quality in crowdsourcing are not yet utilized in such evaluations, which potentially provide reliable evaluations from a different viewpoint. On the other hand, the quality of these aggregated labels is crucial because, when utilizing crowdsourcing, the estimated labels aggregated from multiple crowd labels to the same instances are the eventually collected labels. Therefore, in this paper, we first investigate which existing crowdsourcing datasets can be used for a comparative study and create a benchmark. We then compare the quality between individual crowd labels and {LLM} labels and make the evaluations on the aggregated labels. In addition, we propose a Crowd-{LLM} hybrid label aggregation method and verify the performance. We find that adding {LLM} labels from good {LLMs} to existing crowdsourcing datasets can enhance the quality of the aggregated labels of the datasets, which is also higher than the quality of {LLM} labels themselves.},
	number = {{arXiv}:2401.09760},
	publisher = {{arXiv}},
	author = {Li, Jiyi},
	urldate = {2024-03-17},
	date = {2024-01-18},
	eprinttype = {arxiv},
	eprint = {2401.09760 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/PP7NB7PC/Li - 2024 - A Comparative Study on Annotation Quality of Crowd.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/FFGYLFW9/2401.html:text/html},
}

@misc{shumailov_curse_2023,
	title = {The Curse of Recursion: Training on Generated Data Makes Models Forget},
	url = {http://arxiv.org/abs/2305.17493},
	doi = {10.48550/arXiv.2305.17493},
	shorttitle = {The Curse of Recursion},
	abstract = {Stable Diffusion revolutionised image creation from descriptive text. {GPT}-2, {GPT}-3(.5) and {GPT}-4 demonstrated astonishing performance across a variety of language tasks. {ChatGPT} introduced such language models to the general public. It is now clear that large language models ({LLMs}) are here to stay, and will bring about drastic change in the whole ecosystem of online text and images. In this paper we consider what the future might hold. What will happen to {GPT}-\{n\} once {LLMs} contribute much of the language found online? We find that use of model-generated content in training causes irreversible defects in the resulting models, where tails of the original content distribution disappear. We refer to this effect as Model Collapse and show that it can occur in Variational Autoencoders, Gaussian Mixture Models and {LLMs}. We build theoretical intuition behind the phenomenon and portray its ubiquity amongst all learned generative models. We demonstrate that it has to be taken seriously if we are to sustain the benefits of training from large-scale data scraped from the web. Indeed, the value of data collected about genuine human interactions with systems will be increasingly valuable in the presence of content generated by {LLMs} in data crawled from the Internet.},
	number = {{arXiv}:2305.17493},
	publisher = {{arXiv}},
	author = {Shumailov, Ilia and Shumaylov, Zakhar and Zhao, Yiren and Gal, Yarin and Papernot, Nicolas and Anderson, Ross},
	urldate = {2024-03-17},
	date = {2023-05-31},
	eprinttype = {arxiv},
	eprint = {2305.17493 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/MA98PLPC/Shumailov et al. - 2023 - The Curse of Recursion Training on Generated Data.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/LTI5R8FE/2305.html:text/html},
}

@article{blei_latent_nodate,
	title = {Latent Dirichlet Allocation},
	abstract = {We describe latent Dirichlet allocation ({LDA}), a generative probabilistic model for collections of discrete data such as text corpora. {LDA} is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a ﬁnite mixture over an underlying set of topics. Each topic is, in turn, modeled as an inﬁnite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efﬁcient approximate inference techniques based on variational methods and an {EM} algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classiﬁcation, and collaborative ﬁltering, comparing to a mixture of unigrams model and the probabilistic {LSI} model.},
	author = {Blei, David M},
	langid = {english},
	file = {Blei - Latent Dirichlet Allocation.pdf:/Users/charlesdedampierre/Zotero/storage/3RT6X33E/Blei - Latent Dirichlet Allocation.pdf:application/pdf},
}

@misc{fevotte_algorithms_2011,
	title = {Algorithms for nonnegative matrix factorization with the beta-divergence},
	url = {http://arxiv.org/abs/1010.1763},
	doi = {10.48550/arXiv.1010.1763},
	abstract = {This paper describes algorithms for nonnegative matrix factorization ({NMF}) with the beta-divergence (beta-{NMF}). The beta-divergence is a family of cost functions parametrized by a single shape parameter beta that takes the Euclidean distance, the Kullback-Leibler divergence and the Itakura-Saito divergence as special cases (beta = 2,1,0, respectively). The proposed algorithms are based on a surrogate auxiliary function (a local majorization of the criterion function). We first describe a majorization-minimization ({MM}) algorithm that leads to multiplicative updates, which differ from standard heuristic multiplicative updates by a beta-dependent power exponent. The monotonicity of the heuristic algorithm can however be proven for beta in (0,1) using the proposed auxiliary function. Then we introduce the concept of majorization-equalization ({ME}) algorithm which produces updates that move along constant level sets of the auxiliary function and lead to larger steps than {MM}. Simulations on synthetic and real data illustrate the faster convergence of the {ME} approach. The paper also describes how the proposed algorithms can be adapted to two common variants of {NMF} : penalized {NMF} (i.e., when a penalty function of the factors is added to the criterion function) and convex-{NMF} (when the dictionary is assumed to belong to a known subspace).},
	number = {{arXiv}:1010.1763},
	publisher = {{arXiv}},
	author = {Févotte, Cédric and Idier, Jérôme},
	urldate = {2024-03-17},
	date = {2011-03-08},
	eprinttype = {arxiv},
	eprint = {1010.1763 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/UJUCZ49F/Févotte and Idier - 2011 - Algorithms for nonnegative matrix factorization wi.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/7PAGLMAC/1010.html:text/html},
}

@misc{mikolov_efficient_2013,
	title = {Efficient Estimation of Word Representations in Vector Space},
	url = {http://arxiv.org/abs/1301.3781},
	doi = {10.48550/arXiv.1301.3781},
	abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
	number = {{arXiv}:1301.3781},
	publisher = {{arXiv}},
	author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
	urldate = {2024-03-17},
	date = {2013-09-06},
	eprinttype = {arxiv},
	eprint = {1301.3781 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/KSWQ29T5/Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Ve.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/7VLCVAP2/1301.html:text/html},
}

@misc{le_distributed_2014,
	title = {Distributed Representations of Sentences and Documents},
	url = {http://arxiv.org/abs/1405.4053},
	doi = {10.48550/arXiv.1405.4053},
	abstract = {Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, "powerful," "strong" and "Paris" are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.},
	number = {{arXiv}:1405.4053},
	publisher = {{arXiv}},
	author = {Le, Quoc V. and Mikolov, Tomas},
	urldate = {2024-03-17},
	date = {2014-05-22},
	eprinttype = {arxiv},
	eprint = {1405.4053 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/FPMCSJ7Z/Le and Mikolov - 2014 - Distributed Representations of Sentences and Docum.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/2PYEDZ57/1405.html:text/html},
}

@inproceedings{pennington_glove_2014,
	location = {Doha, Qatar},
	title = {{GloVe}: Global Vectors for Word Representation},
	url = {https://aclanthology.org/D14-1162},
	doi = {10.3115/v1/D14-1162},
	shorttitle = {{GloVe}},
	eventtitle = {{EMNLP} 2014},
	pages = {1532--1543},
	booktitle = {Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})},
	publisher = {Association for Computational Linguistics},
	author = {Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
	editor = {Moschitti, Alessandro and Pang, Bo and Daelemans, Walter},
	urldate = {2024-03-17},
	date = {2014-10},
	file = {Full Text PDF:/Users/charlesdedampierre/Zotero/storage/IHRR9ID3/Pennington et al. - 2014 - GloVe Global Vectors for Word Representation.pdf:application/pdf},
}

@misc{liu_roberta_2019,
	title = {{RoBERTa}: A Robustly Optimized {BERT} Pretraining Approach},
	url = {http://arxiv.org/abs/1907.11692},
	doi = {10.48550/arXiv.1907.11692},
	shorttitle = {{RoBERTa}},
	abstract = {Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of {BERT} pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that {BERT} was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on {GLUE}, {RACE} and {SQuAD}. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.},
	number = {{arXiv}:1907.11692},
	publisher = {{arXiv}},
	author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
	urldate = {2024-03-17},
	date = {2019-07-26},
	eprinttype = {arxiv},
	eprint = {1907.11692 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/M5ES8BKZ/Liu et al. - 2019 - RoBERTa A Robustly Optimized BERT Pretraining App.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/GBCDM8DN/1907.html:text/html},
}

@misc{reimers_sentence-bert_2019,
	title = {Sentence-{BERT}: Sentence Embeddings using Siamese {BERT}-Networks},
	url = {http://arxiv.org/abs/1908.10084},
	doi = {10.48550/arXiv.1908.10084},
	shorttitle = {Sentence-{BERT}},
	abstract = {{BERT} (Devlin et al., 2018) and {RoBERTa} (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity ({STS}). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations ({\textasciitilde}65 hours) with {BERT}. The construction of {BERT} makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-{BERT} ({SBERT}), a modification of the pretrained {BERT} network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with {BERT} / {RoBERTa} to about 5 seconds with {SBERT}, while maintaining the accuracy from {BERT}. We evaluate {SBERT} and {SRoBERTa} on common {STS} tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.},
	number = {{arXiv}:1908.10084},
	publisher = {{arXiv}},
	author = {Reimers, Nils and Gurevych, Iryna},
	urldate = {2024-03-17},
	date = {2019-08-27},
	eprinttype = {arxiv},
	eprint = {1908.10084 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/FCEAUFLC/Reimers and Gurevych - 2019 - Sentence-BERT Sentence Embeddings using Siamese B.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/7CUGXUUV/1908.html:text/html},
}

@misc{angelov_top2vec_2020,
	title = {Top2Vec: Distributed Representations of Topics},
	url = {http://arxiv.org/abs/2008.09470},
	doi = {10.48550/arXiv.2008.09470},
	shorttitle = {Top2Vec},
	abstract = {Topic modeling is used for discovering latent semantic structure, usually referred to as topics, in a large collection of documents. The most widely used methods are Latent Dirichlet Allocation and Probabilistic Latent Semantic Analysis. Despite their popularity they have several weaknesses. In order to achieve optimal results they often require the number of topics to be known, custom stop-word lists, stemming, and lemmatization. Additionally these methods rely on bag-of-words representation of documents which ignore the ordering and semantics of words. Distributed representations of documents and words have gained popularity due to their ability to capture semantics of words and documents. We present \${\textbackslash}texttt\{top2vec\}\$, which leverages joint document and word semantic embedding to find \${\textbackslash}textit\{topic vectors\}\$. This model does not require stop-word lists, stemming or lemmatization, and it automatically finds the number of topics. The resulting topic vectors are jointly embedded with the document and word vectors with distance between them representing semantic similarity. Our experiments demonstrate that \${\textbackslash}texttt\{top2vec\}\$ finds topics which are significantly more informative and representative of the corpus trained on than probabilistic generative models.},
	number = {{arXiv}:2008.09470},
	publisher = {{arXiv}},
	author = {Angelov, Dimo},
	urldate = {2024-03-17},
	date = {2020-08-19},
	eprinttype = {arxiv},
	eprint = {2008.09470 [cs, stat]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/SGFW3IC9/Angelov - 2020 - Top2Vec Distributed Representations of Topics.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/K7DHZYID/2008.html:text/html},
}

@misc{grootendorst_bertopic_2022,
	title = {{BERTopic}: Neural topic modeling with a class-based {TF}-{IDF} procedure},
	url = {http://arxiv.org/abs/2203.05794},
	doi = {10.48550/arXiv.2203.05794},
	shorttitle = {{BERTopic}},
	abstract = {Topic models can be useful tools to discover latent topics in collections of documents. Recent studies have shown the feasibility of approach topic modeling as a clustering task. We present {BERTopic}, a topic model that extends this process by extracting coherent topic representation through the development of a class-based variation of {TF}-{IDF}. More specifically, {BERTopic} generates document embedding with pre-trained transformer-based language models, clusters these embeddings, and finally, generates topic representations with the class-based {TF}-{IDF} procedure. {BERTopic} generates coherent topics and remains competitive across a variety of benchmarks involving classical models and those that follow the more recent clustering approach of topic modeling.},
	number = {{arXiv}:2203.05794},
	publisher = {{arXiv}},
	author = {Grootendorst, Maarten},
	urldate = {2024-03-17},
	date = {2022-03-11},
	eprinttype = {arxiv},
	eprint = {2203.05794 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/4U2X3B23/Grootendorst - 2022 - BERTopic Neural topic modeling with a class-based.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/WWV98YK4/2203.html:text/html},
}

@online{noauthor_visualizing_nodate,
	title = {Visualizing Big Data with augmented and virtual reality: challenges and research agenda {\textbar} Journal of Big Data {\textbar} Full Text},
	url = {https://journalofbigdata.springeropen.com/articles/10.1186/s40537-015-0031-2},
	urldate = {2024-03-17},
	file = {Visualizing Big Data with augmented and virtual reality\: challenges and research agenda | Journal of Big Data | Full Text:/Users/charlesdedampierre/Zotero/storage/XNAXC3HV/s40537-015-0031-2.html:text/html},
}

@online{noauthor_cognitive_nodate,
	title = {Cognitive and psychological science insights to improve climate change data visualization {\textbar} Nature Climate Change},
	url = {https://www.nature.com/articles/nclimate3162},
	urldate = {2024-03-17},
	file = {Cognitive and psychological science insights to improve climate change data visualization | Nature Climate Change:/Users/charlesdedampierre/Zotero/storage/BVZTW8MT/nclimate3162.html:text/html},
}

@online{noauthor_navigating_nodate,
	title = {Navigating cognition: Spatial codes for human thinking {\textbar} Science},
	url = {https://www.science.org/doi/10.1126/science.aat6766},
	urldate = {2024-03-17},
	file = {Navigating cognition\: Spatial codes for human thinking | Science:/Users/charlesdedampierre/Zotero/storage/XLVSNK2V/science.html:text/html},
}

@article{okeefe_hippocampus_1971,
	title = {The hippocampus as a spatial map. Preliminary evidence from unit activity in the freely-moving rat},
	volume = {34},
	issn = {0006-8993},
	doi = {10.1016/0006-8993(71)90358-1},
	pages = {171--175},
	number = {1},
	journaltitle = {Brain Research},
	shortjournal = {Brain Res},
	author = {O'Keefe, J. and Dostrovsky, J.},
	date = {1971-11},
	pmid = {5124915},
	keywords = {Cognition, Animals, Acoustics, Arousal, Behavior, Animal, Cues, Electrodes, Implanted, Electrophysiology, Feeding Behavior, Grooming, Hearing, Hippocampus, Homing Behavior, Light, Limbic System, Locomotion, Motor Activity, Neurons, Odorants, Orientation, Rats, Sleep, Smell, Touch, Vision, Ocular},
}

@inproceedings{agirre_paths_2013,
	location = {Sofia, Bulgaria},
	title = {{PATHS}: A System for Accessing Cultural Heritage Collections},
	url = {https://aclanthology.org/P13-4026},
	shorttitle = {{PATHS}},
	pages = {151--156},
	booktitle = {Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
	publisher = {Association for Computational Linguistics},
	author = {Agirre, Eneko and Aletras, Nikolaos and Clough, Paul and Fernando, Samuel and Goodale, Paula and Hall, Mark and Soroa, Aitor and Stevenson, Mark},
	editor = {Butt, Miriam and Hussain, Sarmad},
	urldate = {2024-03-17},
	date = {2013-08},
	file = {Full Text PDF:/Users/charlesdedampierre/Zotero/storage/JK5XHNTW/Agirre et al. - 2013 - PATHS A System for Accessing Cultural Heritage Co.pdf:application/pdf},
}

@article{nocaj_organizing_2012,
	title = {Organizing Search Results with a Reference Map},
	volume = {18},
	issn = {1941-0506},
	doi = {10.1109/TVCG.2012.250},
	abstract = {We propose a method to highlight query hits in hierarchically clustered collections of interrelated items such as digital libraries or knowledge bases. The method is based on the idea that organizing search results similarly to their arrangement on a fixed reference map facilitates orientation and assessment by preserving a user's mental map. Here, the reference map is built from an {MDS} layout of the items in a Voronoi treemap representing their hierarchical clustering, and we use techniques from dynamic graph layout to align query results with the map. The approach is illustrated on an archive of newspaper articles.},
	pages = {2546--2555},
	number = {12},
	journaltitle = {{IEEE} transactions on visualization and computer graphics},
	shortjournal = {{IEEE} Trans Vis Comput Graph},
	author = {Nocaj, A. and Brandes, U.},
	date = {2012-12},
	pmid = {26357163},
}

@misc{mcinnes_umap_2020,
	title = {{UMAP}: Uniform Manifold Approximation and Projection for Dimension Reduction},
	url = {http://arxiv.org/abs/1802.03426},
	doi = {10.48550/arXiv.1802.03426},
	shorttitle = {{UMAP}},
	abstract = {{UMAP} (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. {UMAP} is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The result is a practical scalable algorithm that applies to real world data. The {UMAP} algorithm is competitive with t-{SNE} for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, {UMAP} has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning.},
	number = {{arXiv}:1802.03426},
	publisher = {{arXiv}},
	author = {{McInnes}, Leland and Healy, John and Melville, James},
	urldate = {2024-03-17},
	date = {2020-09-17},
	eprinttype = {arxiv},
	eprint = {1802.03426 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Computer Science - Computational Geometry},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/QNFU8HK5/McInnes et al. - 2020 - UMAP Uniform Manifold Approximation and Projectio.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/HIEKUPKB/1802.html:text/html},
}

@misc{wang_wizmap_2023,
	title = {{WizMap}: Scalable Interactive Visualization for Exploring Large Machine Learning Embeddings},
	url = {http://arxiv.org/abs/2306.09328},
	doi = {10.48550/arXiv.2306.09328},
	shorttitle = {{WizMap}},
	abstract = {Machine learning models often learn latent embedding representations that capture the domain semantics of their training data. These embedding representations are valuable for interpreting trained models, building new models, and analyzing new datasets. However, interpreting and using embeddings can be challenging due to their opaqueness, high dimensionality, and the large size of modern datasets. To tackle these challenges, we present {WizMap}, an interactive visualization tool to help researchers and practitioners easily explore large embeddings. With a novel multi-resolution embedding summarization method and a familiar map-like interaction design, {WizMap} enables users to navigate and interpret embedding spaces with ease. Leveraging modern web technologies such as {WebGL} and Web Workers, {WizMap} scales to millions of embedding points directly in users' web browsers and computational notebooks without the need for dedicated backend servers. {WizMap} is open-source and available at the following public demo link: https://poloclub.github.io/wizmap.},
	number = {{arXiv}:2306.09328},
	publisher = {{arXiv}},
	author = {Wang, Zijie J. and Hohman, Fred and Chau, Duen Horng},
	urldate = {2024-03-17},
	date = {2023-06-15},
	eprinttype = {arxiv},
	eprint = {2306.09328 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Human-Computer Interaction, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/VAGFKI98/Wang et al. - 2023 - WizMap Scalable Interactive Visualization for Exp.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/QU2PALLI/2306.html:text/html},
}

@online{noauthor_nomic_nodate,
	title = {Nomic Atlas},
	url = {https://atlas.nomic.ai/},
	abstract = {Structure unstructured datasets of text, images, embeddings, audio and video.},
	urldate = {2024-03-17},
	langid = {english},
	file = {Snapshot:/Users/charlesdedampierre/Zotero/storage/3D7WKIMT/atlas.nomic.ai.html:text/html},
}

@article{rosenblatt_remarks_1956,
	title = {Remarks on Some Nonparametric Estimates of a Density Function},
	volume = {27},
	issn = {0003-4851, 2168-8990},
	url = {https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-27/issue-3/Remarks-on-Some-Nonparametric-Estimates-of-a-Density-Function/10.1214/aoms/1177728190.full},
	doi = {10.1214/aoms/1177728190},
	abstract = {This note discusses some aspects of the estimation of the density function of a univariate probability distribution. All estimates of the density function satisfying relatively mild conditions are shown to be biased. The asymptotic mean square error of a particular class of estimates is evaluated.},
	pages = {832--837},
	number = {3},
	journaltitle = {The Annals of Mathematical Statistics},
	author = {Rosenblatt, Murray},
	urldate = {2024-03-17},
	date = {1956-09},
	note = {Publisher: Institute of Mathematical Statistics},
	file = {Full Text PDF:/Users/charlesdedampierre/Zotero/storage/WP9JDHDZ/Rosenblatt - 1956 - Remarks on Some Nonparametric Estimates of a Densi.pdf:application/pdf},
}

@misc{muennighoff_mteb_2023,
	title = {{MTEB}: Massive Text Embedding Benchmark},
	url = {http://arxiv.org/abs/2210.07316},
	doi = {10.48550/arXiv.2210.07316},
	shorttitle = {{MTEB}},
	abstract = {Text embeddings are commonly evaluated on a small set of datasets from a single task not covering their possible applications to other tasks. It is unclear whether state-of-the-art embeddings on semantic textual similarity ({STS}) can be equally well applied to other tasks like clustering or reranking. This makes progress in the field difficult to track, as various models are constantly being proposed without proper evaluation. To solve this problem, we introduce the Massive Text Embedding Benchmark ({MTEB}). {MTEB} spans 8 embedding tasks covering a total of 58 datasets and 112 languages. Through the benchmarking of 33 models on {MTEB}, we establish the most comprehensive benchmark of text embeddings to date. We find that no particular text embedding method dominates across all tasks. This suggests that the field has yet to converge on a universal text embedding method and scale it up sufficiently to provide state-of-the-art results on all embedding tasks. {MTEB} comes with open-source code and a public leaderboard at https://github.com/embeddings-benchmark/mteb.},
	number = {{arXiv}:2210.07316},
	publisher = {{arXiv}},
	author = {Muennighoff, Niklas and Tazi, Nouamane and Magne, Loïc and Reimers, Nils},
	urldate = {2024-03-17},
	date = {2023-03-19},
	eprinttype = {arxiv},
	eprint = {2210.07316 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Information Retrieval, Computer Science - Machine Learning},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/VLKIWPH8/Muennighoff et al. - 2023 - MTEB Massive Text Embedding Benchmark.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/255QB2KS/2210.html:text/html},
}

@misc{rafailov_direct_2023,
	title = {Direct Preference Optimization: Your Language Model is Secretly a Reward Model},
	url = {http://arxiv.org/abs/2305.18290},
	doi = {10.48550/arXiv.2305.18290},
	shorttitle = {Direct Preference Optimization},
	abstract = {While large-scale unsupervised language models ({LMs}) learn broad world knowledge and some reasoning skills, achieving precise control of their behavior is difficult due to the completely unsupervised nature of their training. Existing methods for gaining such steerability collect human labels of the relative quality of model generations and fine-tune the unsupervised {LM} to align with these preferences, often with reinforcement learning from human feedback ({RLHF}). However, {RLHF} is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised {LM} using reinforcement learning to maximize this estimated reward without drifting too far from the original model. In this paper we introduce a new parameterization of the reward model in {RLHF} that enables extraction of the corresponding optimal policy in closed form, allowing us to solve the standard {RLHF} problem with only a simple classification loss. The resulting algorithm, which we call Direct Preference Optimization ({DPO}), is stable, performant, and computationally lightweight, eliminating the need for sampling from the {LM} during fine-tuning or performing significant hyperparameter tuning. Our experiments show that {DPO} can fine-tune {LMs} to align with human preferences as well as or better than existing methods. Notably, fine-tuning with {DPO} exceeds {PPO}-based {RLHF} in ability to control sentiment of generations, and matches or improves response quality in summarization and single-turn dialogue while being substantially simpler to implement and train.},
	number = {{arXiv}:2305.18290},
	publisher = {{arXiv}},
	author = {Rafailov, Rafael and Sharma, Archit and Mitchell, Eric and Ermon, Stefano and Manning, Christopher D. and Finn, Chelsea},
	urldate = {2024-03-17},
	date = {2023-12-13},
	eprinttype = {arxiv},
	eprint = {2305.18290 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/WN8EJ2FM/Rafailov et al. - 2023 - Direct Preference Optimization Your Language Mode.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/JB6CQ6E9/2305.html:text/html},
}

@misc{gallegos_bias_2024,
	title = {Bias and Fairness in Large Language Models: A Survey},
	url = {http://arxiv.org/abs/2309.00770},
	shorttitle = {Bias and Fairness in Large Language Models},
	abstract = {Rapid advancements of large language models ({LLMs}) have enabled the processing, understanding, and generation of human-like text, with increasing integration into systems that touch our social sphere. Despite this success, these models can learn, perpetuate, and amplify harmful social biases. In this paper, we present a comprehensive survey of bias evaluation and mitigation techniques for {LLMs}. We first consolidate, formalize, and expand notions of social bias and fairness in natural language processing, defining distinct facets of harm and introducing several desiderata to operationalize fairness for {LLMs}. We then unify the literature by proposing three intuitive taxonomies, two for bias evaluation, namely metrics and datasets, and one for mitigation. Our first taxonomy of metrics for bias evaluation disambiguates the relationship between metrics and evaluation datasets, and organizes metrics by the different levels at which they operate in a model: embeddings, probabilities, and generated text. Our second taxonomy of datasets for bias evaluation categorizes datasets by their structure as counterfactual inputs or prompts, and identifies the targeted harms and social groups; we also release a consolidation of publicly-available datasets for improved access. Our third taxonomy of techniques for bias mitigation classifies methods by their intervention during pre-processing, in-training, intra-processing, and post-processing, with granular subcategories that elucidate research trends. Finally, we identify open problems and challenges for future work. Synthesizing a wide range of recent research, we aim to provide a clear guide of the existing literature that empowers researchers and practitioners to better understand and prevent the propagation of bias in {LLMs}.},
	number = {{arXiv}:2309.00770},
	publisher = {{arXiv}},
	author = {Gallegos, Isabel O. and Rossi, Ryan A. and Barrow, Joe and Tanjim, Md Mehrab and Kim, Sungchul and Dernoncourt, Franck and Yu, Tong and Zhang, Ruiyi and Ahmed, Nesreen K.},
	urldate = {2024-03-17},
	date = {2024-03-11},
	eprinttype = {arxiv},
	eprint = {2309.00770 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computers and Society},
	file = {arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/9KIASIR3/2309.html:text/html;Full Text PDF:/Users/charlesdedampierre/Zotero/storage/4HRJVQLM/Gallegos et al. - 2024 - Bias and Fairness in Large Language Models A Surv.pdf:application/pdf},
}

@article{kozlowski_geometry_2019,
	title = {The Geometry of Culture: Analyzing Meaning through Word Embeddings},
	volume = {84},
	issn = {0003-1224, 1939-8271},
	url = {http://arxiv.org/abs/1803.09288},
	doi = {10.1177/0003122419877135},
	shorttitle = {The Geometry of Culture},
	abstract = {We demonstrate the utility of a new methodological tool, neural-network word embedding models, for large-scale text analysis, revealing how these models produce richer insights into cultural associations and categories than possible with prior methods. Word embeddings represent semantic relations between words as geometric relationships between vectors in a high-dimensional space, operationalizing a relational model of meaning consistent with contemporary theories of identity and culture. We show that dimensions induced by word differences (e.g. man - woman, rich - poor, black - white, liberal - conservative) in these vector spaces closely correspond to dimensions of cultural meaning, and the projection of words onto these dimensions reflects widely shared cultural connotations when compared to surveyed responses and labeled historical data. We pilot a method for testing the stability of these associations, then demonstrate applications of word embeddings for macro-cultural investigation with a longitudinal analysis of the coevolution of gender and class associations in the United States over the 20th century and a comparative analysis of historic distinctions between markers of gender and class in the U.S. and Britain. We argue that the success of these high-dimensional models motivates a move towards "high-dimensional theorizing" of meanings, identities and cultural processes.},
	pages = {905--949},
	number = {5},
	journaltitle = {American Sociological Review},
	shortjournal = {Am Sociol Rev},
	author = {Kozlowski, Austin C. and Taddy, Matt and Evans, James A.},
	urldate = {2024-03-17},
	date = {2019-10},
	eprinttype = {arxiv},
	eprint = {1803.09288 [cs]},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/Q2LWMRDT/Kozlowski et al. - 2019 - The Geometry of Culture Analyzing Meaning through.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/CDRHXQQA/1803.html:text/html},
}

@inproceedings{piskorski_semeval-2023_2023,
	location = {Toronto, Canada},
	title = {{SemEval}-2023 Task 3: Detecting the Category, the Framing, and the Persuasion Techniques in Online News in a Multi-lingual Setup},
	url = {https://aclanthology.org/2023.semeval-1.317},
	doi = {10.18653/v1/2023.semeval-1.317},
	shorttitle = {{SemEval}-2023 Task 3},
	abstract = {We describe {SemEval}-2023 task 3 on Detecting the Category, the Framing, and the Persuasion Techniques in Online News in a Multilingual Setup: the dataset, the task organization process, the evaluation setup, the results, and the participating systems. The task focused on news articles in nine languages (six known to the participants upfront: English, French, German, Italian, Polish, and Russian), and three additional ones revealed to the participants at the testing phase: Spanish, Greek, and Georgian). The task featured three subtasks: (1) determining the genre of the article (opinion, reporting, or satire), (2) identifying one or more frames used in an article from a pool of 14 generic frames, and (3) identify the persuasion techniques used in each paragraph of the article, using a taxonomy of 23 persuasion techniques. This was a very popular task: a total of 181 teams registered to participate, and 41 eventually made an official submission on the test set.},
	eventtitle = {{SemEval} 2023},
	pages = {2343--2361},
	booktitle = {Proceedings of the 17th International Workshop on Semantic Evaluation ({SemEval}-2023)},
	publisher = {Association for Computational Linguistics},
	author = {Piskorski, Jakub and Stefanovitch, Nicolas and Da San Martino, Giovanni and Nakov, Preslav},
	editor = {Ojha, Atul Kr. and Doğruöz, A. Seza and Da San Martino, Giovanni and Tayyar Madabushi, Harish and Kumar, Ritesh and Sartori, Elisa},
	urldate = {2024-03-17},
	date = {2023-07},
	file = {Full Text PDF:/Users/charlesdedampierre/Zotero/storage/DGDYE8RC/Piskorski et al. - 2023 - SemEval-2023 Task 3 Detecting the Category, the F.pdf:application/pdf},
}

@article{entman_framing_1993,
	title = {Framing: Toward Clarification of a Fractured Paradigm},
	volume = {43},
	issn = {1460-2466},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1460-2466.1993.tb01304.x},
	doi = {10.1111/j.1460-2466.1993.tb01304.x},
	shorttitle = {Framing},
	pages = {51--58},
	number = {4},
	journaltitle = {Journal of Communication},
	author = {Entman, Robert M.},
	urldate = {2024-03-17},
	date = {1993},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1460-2466.1993.tb01304.x},
	file = {Snapshot:/Users/charlesdedampierre/Zotero/storage/WT2MAK5U/j.1460-2466.1993.tb01304.html:text/html},
}

@inproceedings{bhatia_openframing_2021,
	title = {{OpenFraming}: Open-sourced Tool for Computational Framing Analysis of Multilingual Data},
	doi = {10.18653/v1/2021.emnlp-demo.28},
	shorttitle = {{OpenFraming}},
	abstract = {When journalists cover a news story, they can cover the story from multiple angles or perspectives. These perspectives are called "frames", and usage of one frame or another may influence public perception and opinion of the issue at hand. We develop a web-based system for analyzing frames in multilingual text documents. We propose and guide users through a five-step end-to-end computational framing analysis framework grounded in media framing theory in communication research. Users can use the framework to analyze multilingual text data, starting from the exploration of frames in user's corpora and through review of previous framing literature (step 1-3) to frame classification (step 4) and prediction (step 5). The framework combines unsupervised and supervised machine learning and leverages a state-of-the-art ({SoTA}) multilingual language model, which can significantly enhance frame prediction performance while requiring a considerably small sample of manual annotations. Through the interactive website, anyone can perform the proposed computational framing analysis, making advanced computational analysis available to researchers without a programming background and bridging the digital divide within the communication research discipline in particular and the academic community in general. The system is available online at http://www.openframing. org 1 , via an {API} http://www.openframing.org: 5000/docs/, or through our {GitHub} page https: //github.com/vibss2397/{openFraming}.},
	author = {Bhatia, Vibhu and Smith, Alyssa and Akavoor, Vidya and Tofu, David and Ishwar, Prakash and Paik, Sejin and Halim, Edward and Guo, Lei and Yimeng, Sun and Jalal, Mona and Betke, Margrit and Wijaya, Derry},
	date = {2021-11-30},
	file = {Full Text PDF:/Users/charlesdedampierre/Zotero/storage/C56KTPEI/Bhatia et al. - 2021 - OpenFraming Open-sourced Tool for Computational F.pdf:application/pdf},
}

@article{kwak_frameaxis_2021-1,
	title = {{FrameAxis}: Characterizing Microframe Bias and Intensity with Word Embedding},
	volume = {7},
	issn = {2376-5992},
	url = {http://arxiv.org/abs/2002.08608},
	doi = {10.7717/peerj-cs.644},
	shorttitle = {{FrameAxis}},
	abstract = {Framing is a process of emphasizing a certain aspect of an issue over the others, nudging readers or listeners towards different positions on the issue even without making a biased argument. \{Here, we propose {FrameAxis}, a method for characterizing documents by identifying the most relevant semantic axes ("microframes") that are overrepresented in the text using word embedding. Our unsupervised approach can be readily applied to large datasets because it does not require manual annotations. It can also provide nuanced insights by considering a rich set of semantic axes. {FrameAxis} is designed to quantitatively tease out two important dimensions of how microframes are used in the text. {\textbackslash}textit\{Microframe bias\} captures how biased the text is on a certain microframe, and {\textbackslash}textit\{microframe intensity\} shows how actively a certain microframe is used. Together, they offer a detailed characterization of the text. We demonstrate that microframes with the highest bias and intensity well align with sentiment, topic, and partisan spectrum by applying {FrameAxis} to multiple datasets from restaurant reviews to political news.\} The existing domain knowledge can be incorporated into {FrameAxis} \{by using custom microframes and by using {FrameAxis} as an iterative exploratory analysis instrument.\} Additionally, we propose methods for explaining the results of {FrameAxis} at the level of individual words and documents. Our method may accelerate scalable and sophisticated computational analyses of framing across disciplines.},
	pages = {e644},
	journaltitle = {{PeerJ} Computer Science},
	author = {Kwak, Haewoon and An, Jisun and Jing, Elise and Ahn, Yong-Yeol},
	urldate = {2024-03-17},
	date = {2021-07-22},
	eprinttype = {arxiv},
	eprint = {2002.08608 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Computers and Society, I.2.7},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/CDI26C7H/Kwak et al. - 2021 - FrameAxis Characterizing Microframe Bias and Inte.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/JHZCZN7I/2002.html:text/html},
}

@incollection{jose_exploration_2017,
	location = {Cham},
	title = {Exploration of a Threshold for Similarity Based on Uncertainty in Word Embedding},
	volume = {10193},
	isbn = {978-3-319-56607-8 978-3-319-56608-5},
	url = {http://link.springer.com/10.1007/978-3-319-56608-5_31},
	abstract = {Word embedding promises a quantiﬁcation of the similarity between terms. However, it is not clear to what extent this similarity value can be of practical use for subsequent information access tasks. In particular, which range of similarity values is indicative of the actual term relatedness? We ﬁrst observe and quantify the uncertainty of word embedding models with respect to the similarity values they generate. Based on this, we introduce a general threshold which effectively ﬁlters related terms. We explore the effect of dimensionality on this general threshold by conducting the experiments in different vector dimensions. Our evaluation on four test collections with four relevance scoring models supports the effectiveness of our approach, as the results of the proposed threshold are signiﬁcantly better than the baseline while being equal to, or statistically indistinguishable from, the optimal results.},
	pages = {396--409},
	booktitle = {Advances in Information Retrieval},
	publisher = {Springer International Publishing},
	author = {Rekabsaz, Navid and Lupu, Mihai and Hanbury, Allan},
	editor = {Jose, Joemon M and Hauff, Claudia and Altıngovde, Ismail Sengor and Song, Dawei and Albakour, Dyaa and Watt, Stuart and Tait, John},
	urldate = {2024-03-17},
	date = {2017},
	langid = {english},
	doi = {10.1007/978-3-319-56608-5_31},
	note = {Series Title: Lecture Notes in Computer Science},
	file = {Rekabsaz et al. - 2017 - Exploration of a Threshold for Similarity Based on.pdf:/Users/charlesdedampierre/Zotero/storage/FZ8FMMFE/Rekabsaz et al. - 2017 - Exploration of a Threshold for Similarity Based on.pdf:application/pdf},
}

@misc{kwon_efficient_2023,
	title = {Efficient Memory Management for Large Language Model Serving with {PagedAttention}},
	url = {http://arxiv.org/abs/2309.06180},
	doi = {10.48550/arXiv.2309.06180},
	abstract = {High throughput serving of large language models ({LLMs}) requires batching sufficiently many requests at a time. However, existing systems struggle because the key-value cache ({KV} cache) memory for each request is huge and grows and shrinks dynamically. When managed inefficiently, this memory can be significantly wasted by fragmentation and redundant duplication, limiting the batch size. To address this problem, we propose {PagedAttention}, an attention algorithm inspired by the classical virtual memory and paging techniques in operating systems. On top of it, we build {vLLM}, an {LLM} serving system that achieves (1) near-zero waste in {KV} cache memory and (2) flexible sharing of {KV} cache within and across requests to further reduce memory usage. Our evaluations show that {vLLM} improves the throughput of popular {LLMs} by 2-4\${\textbackslash}times\$ with the same level of latency compared to the state-of-the-art systems, such as {FasterTransformer} and Orca. The improvement is more pronounced with longer sequences, larger models, and more complex decoding algorithms. {vLLM}'s source code is publicly available at https://github.com/vllm-project/vllm},
	number = {{arXiv}:2309.06180},
	publisher = {{arXiv}},
	author = {Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph E. and Zhang, Hao and Stoica, Ion},
	urldate = {2024-03-17},
	date = {2023-09-12},
	eprinttype = {arxiv},
	eprint = {2309.06180 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Distributed, Parallel, and Cluster Computing},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/XI4R4FMC/Kwon et al. - 2023 - Efficient Memory Management for Large Language Mod.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/5SCKEEYA/2309.html:text/html},
}

@misc{cai_theoretical_2022,
	title = {Theoretical Foundations of t-{SNE} for Visualizing High-Dimensional Clustered Data},
	url = {http://arxiv.org/abs/2105.07536},
	doi = {10.48550/arXiv.2105.07536},
	abstract = {This paper investigates the theoretical foundations of the t-distributed stochastic neighbor embedding (t-{SNE}) algorithm, a popular nonlinear dimension reduction and data visualization method. A novel theoretical framework for the analysis of t-{SNE} based on the gradient descent approach is presented. For the early exaggeration stage of t-{SNE}, we show its asymptotic equivalence to power iterations based on the underlying graph Laplacian, characterize its limiting behavior, and uncover its deep connection to Laplacian spectral clustering, and fundamental principles including early stopping as implicit regularization. The results explain the intrinsic mechanism and the empirical benefits of such a computational strategy. For the embedding stage of t-{SNE}, we characterize the kinematics of the low-dimensional map throughout the iterations, and identify an amplification phase, featuring the intercluster repulsion and the expansive behavior of the low-dimensional map, and a stabilization phase. The general theory explains the fast convergence rate and the exceptional empirical performance of t-{SNE} for visualizing clustered data, brings forth interpretations of the t-{SNE} visualizations, and provides theoretical guidance for applying t-{SNE} and selecting its tuning parameters in various applications.},
	number = {{arXiv}:2105.07536},
	publisher = {{arXiv}},
	author = {Cai, T. Tony and Ma, Rong},
	urldate = {2024-03-18},
	date = {2022-10-31},
	eprinttype = {arxiv},
	eprint = {2105.07536 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Mathematics - Statistics Theory},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/43EY66SA/Cai and Ma - 2022 - Theoretical Foundations of t-SNE for Visualizing H.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/BGKGVF7R/2105.html:text/html},
}

@misc{liu_datasets_2024,
	title = {Datasets for Large Language Models: A Comprehensive Survey},
	url = {http://arxiv.org/abs/2402.18041},
	doi = {10.48550/arXiv.2402.18041},
	shorttitle = {Datasets for Large Language Models},
	abstract = {This paper embarks on an exploration into the Large Language Model ({LLM}) datasets, which play a crucial role in the remarkable advancements of {LLMs}. The datasets serve as the foundational infrastructure analogous to a root system that sustains and nurtures the development of {LLMs}. Consequently, examination of these datasets emerges as a critical topic in research. In order to address the current lack of a comprehensive overview and thorough analysis of {LLM} datasets, and to gain insights into their current status and future trends, this survey consolidates and categorizes the fundamental aspects of {LLM} datasets from five perspectives: (1) Pre-training Corpora; (2) Instruction Fine-tuning Datasets; (3) Preference Datasets; (4) Evaluation Datasets; (5) Traditional Natural Language Processing ({NLP}) Datasets. The survey sheds light on the prevailing challenges and points out potential avenues for future investigation. Additionally, a comprehensive review of the existing available dataset resources is also provided, including statistics from 444 datasets, covering 8 language categories and spanning 32 domains. Information from 20 dimensions is incorporated into the dataset statistics. The total data size surveyed surpasses 774.5 {TB} for pre-training corpora and 700M instances for other datasets. We aim to present the entire landscape of {LLM} text datasets, serving as a comprehensive reference for researchers in this field and contributing to future studies. Related resources are available at: https://github.com/lmmlzn/Awesome-{LLMs}-Datasets.},
	number = {{arXiv}:2402.18041},
	publisher = {{arXiv}},
	author = {Liu, Yang and Cao, Jiahuan and Liu, Chongyu and Ding, Kai and Jin, Lianwen},
	urldate = {2024-04-15},
	date = {2024-02-27},
	eprinttype = {arxiv},
	eprint = {2402.18041 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:/Users/charlesdedampierre/Zotero/storage/EDPS43HX/Liu et al. - 2024 - Datasets for Large Language Models A Comprehensiv.pdf:application/pdf;arXiv.org Snapshot:/Users/charlesdedampierre/Zotero/storage/753D5WY7/2402.html:text/html},
}
